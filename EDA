---
editor_options: 
  markdown: 
    wrap: sentence
---

```{r, include=FALSE}
# Preliminaries
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(maps)
# library(countrycode)
library(leaflet)
#library(geojsonio)
library(viridis)
library(magick) # for including a .png in plots
TA_logo <- image_read("plot/TA_logo.png")
# library(gghighlight)
library(GGally)
library(ggrepel)
```

\newpage

# Exploratory Data Analysis

Before you can dive into the data, you need to do two things. 
First of all, you need to request your personal data from Netflix, which can take a few days. Therefore, you should ask for your data as early as possible. 

::: {.tips .r data-latex="r"}
In your workspace on [RStudio Cloud](https://rstudio.cloud/projects), we have already uploaded an "assignment" for you (Template HoneyAndBees).
When you create a new project within the workspace *Class of '22 \| TechAcademy \| Data Science with R*, your workspace will open up.

We've already made some arrangements for you: The data sets you will be working with throughout the project are already available in your working directory.
We also created an RMarkdown file (a file that ends with `.Rmd` extension), with which you will be able to create a detailed report of your project.
You can convert that file into an HTML document when you have finished coding the project in R.
Open the file `Markdown_HoneyAndBees.Rmd` and see for yourself!
:::

::: {.tipsp .python data-latex="p"}
We recommend using [Google Colab](https://colab.research.google.com) for this project since it requires no particular setup, stores its notebooks to your Google Drive, and makes it easy for you to share them with your team members.

As an alternative to Google Colab, you might want to install Jupyter Notebook locally using the Anaconda distribution.
We will give you a more detailed step-by-step demo during the first coding meetup.
:::

Next up is importing the data sets. It's best to this **once** on the top
level of your notebook / script. You can always copy to new variables and work on slices of the data frames afterwards.

* [Netflix](https://drive.google.com/uc?export=download&id=1bQtWQluwwGUIgZuDOsJOE-4Om7x4HOxP)

## Getting started
### Discovering the Data
The first big step is importing a general Netflix data set into your coding environment: 
[Netflix]
Once done, let’s start by looking at the Netflix data set.
*Have a look at the columns of the data set and their “values” 
*Do you see any missing values or data entries that are different from the other entries?
*What are the data formats (e.g. data types)?
*Look at the date_added columns. Do you see any critical aspects of the data?
Write down a couple of sentences to these questions, the goal is to show (your readers) what you are seeing. Also, comment on any errors or irregularities which you notice and that could be an issue later on in the project. 


::: {.tips .r data-latex="r"}
You can import all data files directly from your working directory by, for examples, using the command netflix_general <- read_csv("Netflix.csv"). However it has to be the correct path. Use head() and glimpse() or class()(on a specific colum) to get an overview.
Lastly, get a quick summary of the data using {base} R’s summary() or {psych}’s describe() function. To find more ways to generate quick data summaries in R, check this blog post from Adam Medcalf.
If you need some additional, more general information on how to import data and different data types, check out this cheat sheet.:::

::: {.tipsp .python data-latex="p"}
You can feed the links to the respective data files above to a method of the pandas package (you might want to specify the index column). Check out the resulting pd.DataFrame instance with the head() method and the dtpyes attribute. You can also dig into a specific column with describe(). Here’s an additional pandas cheat sheet for you to reference
:::


### Give some overall statements 

Now that you have imported the data set, let's have a deeper look. Since you already got a feeling by now, it would be interesting to indicate some outstanding features (based on the uncleaned and untransfomated dataset):
*What's the longest movie (not TV show) included in the dataset?
(Look very clearly if your result is valid)
*Which country released the most content (movies and tv shows)?
*How many movies and tv shows are included? Try to do a simple plot here so you can see the distribution. If you cannot plot it just now, come back later to finish this.

::: {.tips .r data-latex="r"}
You could use {dplyr}’s select, filter, count and arrange function to compute the desired outcome to answer the question. If you haven’t heard of the {dplyr} package yet, take the respective DataCamp course!
For the plot, look at {ggplot} and then call geom_bar(). {ggplot2}’s syntax is perhaps a bit harder to learn at the start, but it gives you more plotting benefits in the long run. If you haven’t heard of the {ggplot2} package yet, take the respective DataCamp course
:::

## Data Cleaning and Useful Transformations
### Date Formatting
From exploring the data in the previous tasks you might have noticed that the time and dates are not in a date format. In order to fix this, convert the “date_added” and “release_year” column into date format.  

::: {.tips .r data-latex="r"}
You can use the lubridate package to transform the column into a date format. To make things easier, check out the lubridate package cheat sheet. If you would like to read up on some general information on date formats with R in your spare time, have a look here. Converting the release year might take two steps.
:::

### More details of the longest movie

So far, you have converted the column into a more appropriate format for further investigations. Can you also fix the duration of the movies into a numeric format? 
Can you tell now what the longest movie is? On the concept of distribution, you should also try to compute the mean and standard deviation of the movie duration in minutes.

::: {.tips .r data-latex="r"}
First off, you might want to create a separate data frame for the movies so the tv shows do not bother you further. Use the filter call here. 
Next you might have recognized the “min” appendix. This can be deleted with the “gsub” call. With the help of mutate you can convert the column into numeric values and arrange the movies descending. 
For the mean and standard deviation simply use {base} R’s mean() function to compute a mean of any column in R. Similarly, R comes with the sd() function to calculate the standard deviation of a column. You can combine these two functions, e.g., in a {dplyr}’s summarise() verb
:::

::: {.tipsp .python data-latex="p"}
`pd.to_datetime()` is what I would look at for example.
A corresponding DataCamp resource is section 4 in [Working with dates and times in Python](https://app.datacamp.com/learn/courses/working-with-dates-and-times-in-python).
Also, the [Data Manipulation with pandas](https://app.datacamp.com/learn/courses/data-manipulation-with-pandas) course is of great help for the following exercises.
:::

### A histogram of the top 10 longest movies duration

Visualizing data is essential to facilitate perception and to understand information: Create a graph to visualize the top 10 longest movies.
We focus on creating a histogram in the tips section since it’s perhaps the most common approach for plotting. You can, however, choose a different chart type; just make sure that the information you want to display is clear and correct. However, as in school, always add axis labels when possible.

::: {.tips .r data-latex="r"}
If your data is saved as a dataframe you can perceive with the data from the previous task. Use {ggplot2} to create a histogram. Integrate top_n() before the ggplot call and select  geom_col() to achieve a histogram presentation.
:::

::: {.tipsp .python data-latex="p"}
You need an iterable to loop over, the semicolon after the keyword, and the indentation of the subsequent lines!
Here is a [cheat sheet](https://drive.google.com/file/d/15DwPt5r_vySfuWdOAvci71bDSnD7533P/view?usp=sharing) in case you have forgotten.
:::

### Visualizing movie durations over time

While we are at the topic of movie durations, it might also be interesting to see how the average movie length evolved: Choose and plot the chart you think is most appropriate for displaying this type of information.
After plotting, please comment and interpret the graph: Were there any significant increases/decreases in movie length over time? If so, what could be the reason?

::: {.tips .r data-latex="r"}
Again, it's ggplot’s turn. Instead of preparing the summarise() and mean() functions combination you can also directly integrate the adjustments in the geom_bar call with (stat = "summary", fun = "mean"). 
:::

## Your personal data
### Load your data 

You will now use the data set which you requested from Netflix. In the Netflix folder you will find the document of interest: ViewingActivity. Load this in your environment and inspect it as you did before with the Netflix Dataset.
If you can’t request your data, ask your mentor; they will provide you with an alternative data set.


### Clean and transform dataset

As you might have noticed, Netflix recorded every time you clicked on a movie even if you didn’t watch it. Check which column indicates those with a specific value. To avoid a bias in the following analysis, delete the respective rows. You can further drop columns that seem unnecessary or don’t give any information and change column names if you wish.
Additionally, convert the column Duration in minutes (round them) and extract the viewing day and viewing time from “Start time” into two separate columns (e.g., “date” and “time”).

::: {.tips .r data-latex="r"}
mutate and filter are your best friends in this cleaning process. 
:::

::: {.tipsp .python data-latex="p"}
We highly recommend the [Datacamp course on missing values in Python](https://www.datacamp.com/courses/dealing-with-missing-data-in-python) for this exercise.
:::


### Merging datasets : primitive approach

As a data scientist, you’ll often find yourself working with data sets from different data sources referencing the same object. For example, you might have the movie names in one file and the respective genre in a separate file. It would make more sense to just merge the two data sets into one. Indeed, this is the case with our data. Your Netflix data does not provide information on genre, actor, or director, while the general Netflix data set does. So, to make life easier for the upcoming tasks, you’ll now need to merge both data sets by the title name. 

There are several things kind of “wrong” with the merged data set. What is it and why?
Tipp: You need to prepare the dataset in a way that the title, session and episode will be split into a column of title, session and episode separately in order for the two data frames to join each other properly. Some calls that can be helpful

::: {.tips .r data-latex="r"}
calls such as separate, ifelse and rename are suitable here. Merging can be done in several ways. You could, e.g., use {dplyr}’s left_join() to combine the two data sets  based on the “left sided” dataset. Which one should be the “left-sided”?
:::


###  Merging datasets : advanced approach

You might have noticed that merging the data set is a little challenging. This is because Netflix sometimes displays title, session and episode in a remixed way and also because your Netflix data might be in German whereas the general Netflix Data is in English. We fixed this issue externally and you can now send your data to Moritz Schwerdt, who will provide you with a respective general Netflix dataset.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width = "100%"}
knitr::include_graphics("plot/Lost Colonies in Wyoming over time.jpg")
```

### Dynamic line plot

Your goal for this task is to plot how each viewer’s activity was recorded over time. Since it would be a bit unclear in a static plot, let's try to do a dynamic chart here! 

::: {.tips .r data-latex="r"}
The data is already ready for this. Your ggplot() call might need some more input than you used before. As the graphic is supposed to be a line with points geom_line() and geom_point () will be a good choice of combination. The dynamic aspect is no magic, you just need to add the transition_reveal() call. 
:::

::: {.tipsp .python data-latex="p"}
Column names can be replaced very neatly by passing a dictionary `{"x": "y", }` to a certain pandas method.
:::

## Let’s get personal

We dived into the provided Netflix data set and a bit into your overall personal dataset, but now is the time to look into your own Netflix history.
First, we want to look at the longest movie you have ever watched, afterward, into your general and binge-watching behavior.
We recommend using Tobi's data if you are currently working with the Netflix data set provided from us.

So, what's the longest movie you have ever watched? Maybe you also want to check the day? Do you remember that day?

::: {.tips .r data-latex="r"}
filter, select and arrange will do a good job here.
:::

::: {.tipsp .python data-latex="p"}
Check out the pandas [merge function](https://pandas.pydata.org/docs/reference/api/pandas.merge.html) documentation.
If it helps you, visualize what the identifiers in each table are and how they relate to each other. 
The DataCamp course [Joining Data with pandas (4h)](https://app.datacamp.com/learn/courses/joining-data-with-pandas) might also get you started.
:::

### Monthly viewing time in 2021

Let’s get a little fancy by displaying the monthly average time you watched in 2021 (or another year of your choice). 

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width = "100%"}
knitr::include_graphics("plot/Starting Colonies in 2020.jpg")
```

::: {.tips .r data-latex="r"}
This task involves three steps. First, you want to extract the month from the “start_time” column, where lubridate will help you. You can then use the group_by argument to group the dataset by the month and filter for a specific year. After that, you can pipe along and directly add the third step: your ggplot call. Now, you can visualize your output however you want. However, the presented output is obtained by combining geom_col + coord_polar().
:::

::: {.tipsp .python data-latex="p"}
In case you want to filter a certain year check out [`.loc` indexing](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html).
Afterwards you are looking for [matplotlib's horizontal bar plot](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.barh.html). Should you get stuck adding the lines to the plot, you can look at the following [stackoverflow question](https://stackoverflow.com/questions/33382619/plot-a-horizontal-line-using-matplotlib).
Oftentimes, when you want to create plots that are a little bit more elaborate, you will find an initial statement like this:

    # import statement on top, of course
    from matplotlib import pyplot as plt
    fig, ax = plt.subplots()

The trick is to add to the generated `Figure` and `Axes` object subsequently.
For further resources the course [Introduction to Data Visualization with Matplotlib (4h)](https://app.datacamp.com/learn/courses/introduction-to-data-visualization-with-matplotlib) is a good place to start!
:::


### Average per weekday

Our subsequent interest lies in analyzing the viewing time of specific weekdays. Either choose the whole year or a month of your interest and look at the weekday average. On which days have you watched more Netflix, can you see a peak?
For our advanced programmers: Would it not be interesting to look at what time of the day you watch the most?

::: {.tips .r data-latex="r"}
As before, you now want to extract the weekday from the “start_time”. Further you might want to filter for a specific month or year and group by date and weekday. You will then need to sum the minutes per day and group again by weekday to summarize for the mean of the duration. Finally, you could, for example, plot a classic ggplot.
:::

::: {.tipsp .python data-latex="p"}
Make sure to sort your state index first, afterwards make use of `numpy's` `array_split(df, x)` function (it never hurts to make a sanity check/print afterwards).
:::

## Binge watching

In this section, the goal should be to create a plot of your top 10 binge tv shows. Before you begin, you need to decide what binge watching means to you. We decided it’s at least 1 hour of a TV show per day. But you should adjust that to your watching behavior.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%"}
knitr::include_graphics("plot/Log Honey Production.jpg")
knitr::include_graphics("plot/Varroa Mites.jpg")
```
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.show="hold", out.width="50%"}
knitr::include_graphics("plot/Log Lost Bee Colonies.jpg")
knitr::include_graphics("plot/Average Precipitation.jpg")
```


::: {.tips .r data-latex="r"}
Again, you could use the familiar {dplyr} verbs for this part. You first want to filter for TV Shows and group by date and title. You then need to count episodes and minutes per day and group again by title. Now, calculate the sum of episodes and minutes per day. Here you might want to convert minutes into hours. Finally, arrange everything descending. 
For the plot, you can use ggplots geom_col or whatever you think is best to present your binge series
:::

::: {.tipsp .python data-latex="p"}
Surprise, you are looking for the `.boxplot(...)` function!
:::


## Scatterplot with marginal density

You have computed and visualized your favorite binge tv shows, but how has your watching behavior developed on Netflix since you first used it? This question is something we want to analyze now. There are different possibilities to explore this question. We will start by visualizing it via a scatterplot with marginal density. Include all the profile names for this task and make a visual comparison. What can the plot tell us about your watching behavior?


## Word cloud with your favorite genre 

Until now, even though we merged the two data sets, analyzing the Netflix movies was possible by only using each one. Let's change that! Generate a word cloud with your personal most watched genres! Is it what you expected it to be?

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width = "100%"}
knitr::include_graphics("plot/Map_with_Popups.png")
```

::: {.tips .r data-latex="r"}
Install the package "wordcloud" and start preparing your joined dataset. We are only interested in the "listed_in" column now. Use the mutate function to do a structure split, so each genre will get its row instead of being separated by a comma. Add unnest to your call. Extract the column and fix possible issues (e.g., white space). An easy way is to use the table() call on the listed_in and change the table directly into a data frame. 
For the word cloud, set a seed if you want to get the same cloud every time you run the code. The call wordcloud only needs to be filled with the respective word and frequency column. Feel free to spice it up!
:::

::: {.tipsp .python data-latex="p"}
We are going to use yet another library, this one is called `folium`.

For this task you need to work with its documentation which you can find online.

Use folium’s Circle (Marker) to draw a circle for each state at its centered coordinates (latitude, longitude). You will need to implement a for-loop to iterate over all states. 
    
    import folium
    # Initiate the map
    m = folium.Map(
        location=[39, -101],  # Somewhat central U.S.A
        zoom_start=3.5,
        tiles='Stamen Terrain'  # one of many Map Styles
    )
    
    # Use a for-loop to plot circles
    for idx, row in df.iterrows() :
        # Your code here
    
    m  # Displays the map


:::


## Surprise Us! 
This section only scratches the surface of what is possible with your Netflix data and some columns haven't even been analyzed. Have you discovered anything cool and/or want to experiment with a new visualization technique to deliver a message? Here is the right place to put down anything you did and would like to do with the project that did not quite fit in the other exercise sections. If you are looking for some visualization inspiration, check out this page.
Congratulations! Based on your work with fundamental data transformations and many visualizations, you now have a solid understanding of the Netflix data sets and your personal data! With this, you have completed the EDA part of the project! Don’t forget to send your project results to our project submission email address (projekt@tech-academy.io) before the deadline (05.02.2023, 23:59). Thanks for being a part of TechAcademy!
If you are in the advanced track your coding journey goes on with the next section!
